{
  "session_id": "ab7fe786-4677-407e-a2bc-59ae1d2fbca2",
  "survey_type": "adoption",
  "status": "completed",
  "participant": {
    "name": "Mark Gill",
    "email": "mcgill@stcloudstate.edu",
    "start_time": "2025-12-07T03:01:02.449Z"
  },
  "conversation": [
    {
      "role": "assistant",
      "content": "Hi Mark Gill! Thanks for taking time to explore possibilities for integrating AI into your teaching.\n\nI'm here to have a genuine conversation about your course, your concerns, and what you're hoping to achieve. This isn't about convincing you to use AI - it's about understanding your situation and what would need to be true for AI to be helpful rather than problematic.\n\nA few things to know:\n\n• This conversation will take 15-20 minutes depending on how much you want to share\n• There are no right or wrong answers - complexity and uncertainty are welcome\n• I won't offer solutions or prescriptions - this is about listening and understanding\n• Everything you share will be saved for the NextEd team to review\n• You can end whenever you're ready using the \"I'm Done\" button\n\nLet's start with the basics: Which course are you thinking about redesigning?",
      "timestamp": "2025-12-07T03:01:02.453Z"
    },
    {
      "role": "user",
      "content": "SE 266, Game scripting with Unity",
      "timestamp": "2025-12-07T03:01:20.534Z"
    },
    {
      "role": "assistant",
      "content": "Thanks for sharing that! SE 266 - Game scripting with Unity sounds like a hands-on technical course. \n\nWhere does this fit in your program - is this more of an introductory course where students are learning scripting fundamentals, or are they coming in with programming experience and this is about applying those skills specifically to game development?",
      "timestamp": "2025-12-07T03:01:25.443Z"
    },
    {
      "role": "user",
      "content": "It's an introductory course. A 200-level elective with object-oriented programming its only prereq.",
      "timestamp": "2025-12-07T03:02:26.827Z"
    },
    {
      "role": "assistant",
      "content": "Got it - so students come in with OOP foundations but this is their first dive into game scripting and Unity. \n\nIn a sentence or two, what is this course really about for you? Is it primarily about learning Unity's tools and C# scripting, or is there something bigger you're trying to accomplish with game development as the vehicle?",
      "timestamp": "2025-12-07T03:02:31.236Z"
    },
    {
      "role": "user",
      "content": "Unity is such a complex environment.  I barely have time to cover the editor in a semester much less the finer points of game design.",
      "timestamp": "2025-12-07T03:03:35.046Z"
    },
    {
      "role": "assistant",
      "content": "That complexity challenge sounds really frustrating - Unity has so many layers and systems that it's hard to know what to prioritize in a single semester.\n\nWhat do you want students to remember about this course for the rest of their lives? Is it mastery of Unity specifically, confidence with game development concepts more broadly, or something else that would make the course worthwhile even if they never touch Unity again?",
      "timestamp": "2025-12-07T03:03:39.787Z"
    },
    {
      "role": "user",
      "content": "What I'd really want them to come away with is how software can be seen as being made up of building blocks, that learning how to assemble those blocks is more important than the code inside the blocks.",
      "timestamp": "2025-12-07T03:05:15.019Z"
    },
    {
      "role": "assistant",
      "content": "That's a beautiful way to think about it - the architectural thinking and composition skills that transfer everywhere, not just the Unity-specific syntax.\n\nWhen students do struggle in your course, what tends to trip them up most? Is it getting lost in Unity's interface complexity, difficulty connecting the building block concepts to what they're actually doing, or something else entirely?",
      "timestamp": "2025-12-07T03:05:20.359Z"
    },
    {
      "role": "user",
      "content": "the complexity of a 3D environment, all of the different moving parts, lights, materials, animations, scripting...",
      "timestamp": "2025-12-07T03:06:09.500Z"
    },
    {
      "role": "assistant",
      "content": "That makes total sense - they're trying to learn the building block philosophy while simultaneously being overwhelmed by lights, materials, physics, animation systems, and everything else Unity throws at them.\n\nWhen you think about using AI in this course, what gives you the most pause - questions about pedagogy and learning, questions about institutional policy and compliance, or both equally?",
      "timestamp": "2025-12-07T03:06:13.153Z"
    },
    {
      "role": "user",
      "content": "I'm concerned about student access.  I'm also concerned about student acceptance of AI. Many students in our program are vehemently against AI",
      "timestamp": "2025-12-07T03:07:08.445Z"
    },
    {
      "role": "assistant",
      "content": "Those are really important concerns - both the practical equity issue of access and the very real resistance you're seeing from students.\n\nOn the access side, are you thinking about economic barriers to AI tools, or are there other access issues that worry you? And with the student resistance - do you get a sense of what's driving that opposition? Is it more about academic integrity concerns, broader ethical issues with AI, or something else?",
      "timestamp": "2025-12-07T03:07:13.128Z"
    },
    {
      "role": "user",
      "content": "We have policies around AI usage I don't fully understand.  We have Copilot, but that's about all I know we have.",
      "timestamp": "2025-12-07T03:08:21.386Z"
    },
    {
      "role": "assistant",
      "content": "That policy uncertainty makes everything more complicated - hard to design anything thoughtfully when you're not sure what the boundaries are.\n\nDo institutional policies around AI make it harder for you to experiment and adopt AI thoughtfully, or would clearer boundaries actually make it easier to figure out what's possible within your course?",
      "timestamp": "2025-12-07T03:08:25.295Z"
    },
    {
      "role": "user",
      "content": "they get in the way to be sure.",
      "timestamp": "2025-12-07T03:09:05.331Z"
    },
    {
      "role": "assistant",
      "content": "We're about halfway through - thanks for staying with me. It sounds like the policies create barriers rather than helpful guardrails.\n\nWhen you imagine trying something with AI in your course - even just hypothetically - are you more worried about accidentally violating unclear policies, or about pushback from students who are already resistant to AI, or both equally?",
      "timestamp": "2025-12-07T03:09:10.330Z"
    },
    {
      "role": "user",
      "content": "Both bother me, really.  And then there's the whole plagiarism thing.",
      "timestamp": "2025-12-07T03:09:44.302Z"
    },
    {
      "role": "assistant",
      "content": "That's a lot to navigate - unclear institutional boundaries, student resistance, and now the academic integrity questions on top of everything else.\n\nWhen you think about the plagiarism concern specifically, are you worried about students using AI to generate code they don't understand (which would undermine your building blocks learning goal), or more about the detection and enforcement side of things, or both?",
      "timestamp": "2025-12-07T03:09:49.206Z"
    },
    {
      "role": "user",
      "content": "It all of that.. and where did the training data come from? Did AI steal all those ideas?",
      "timestamp": "2025-12-07T03:10:34.618Z"
    },
    {
      "role": "assistant",
      "content": "The training data question adds another whole layer - the ethics of how these AI systems were built in the first place, on top of all the classroom concerns.\n\nIt sounds like you're carrying a lot of different worries about this - policy uncertainty, student resistance, academic integrity, and now the broader ethical questions about AI development itself. Do you see AI as fundamentally incompatible with what you're trying to teach about building blocks and software architecture, or as something that could potentially work with very careful design, or are you somewhere in between?",
      "timestamp": "2025-12-07T03:10:39.740Z"
    },
    {
      "role": "user",
      "content": "I don't think it's fundamentally incompatable... it's just something we have to figure out",
      "timestamp": "2025-12-07T03:11:17.940Z"
    },
    {
      "role": "assistant",
      "content": "That \"we have to figure it out\" feeling captures something really important - you're not dismissing it outright, but there's a lot of uncertainty to work through.\n\nBeyond all the concerns we've talked about - policies, student resistance, plagiarism, ethics - what's the biggest practical obstacle if you were to actually experiment with something? Is it time and workload on your end, your own comfort level with AI tools, or something else entirely?",
      "timestamp": "2025-12-07T03:11:23.718Z"
    },
    {
      "role": "user",
      "content": "the biggest obstacle is just knowing which direction to move in first.",
      "timestamp": "2025-12-07T03:11:56.004Z"
    },
    {
      "role": "assistant",
      "content": "That directional uncertainty makes complete sense - with all these competing concerns and constraints, it's hard to know what a good first step even looks like.\n\nIf you were to experiment, would you rather start with small changes to what you're already doing, redesign a specific component or assignment, or does it completely depend on what direction feels right once you figure that out?",
      "timestamp": "2025-12-07T03:12:00.164Z"
    },
    {
      "role": "user",
      "content": "I'm open to completely designing a new course from scratch.",
      "timestamp": "2025-12-07T03:12:41.361Z"
    },
    {
      "role": "assistant",
      "content": "That's a big shift - going from \"which direction to move in first\" to potentially redesigning from the ground up. That suggests you might be more ready for substantial change than incremental tweaks.\n\nHave you actually tried using AI tools in your teaching yet - maybe some experiments or more substantial integration - or is this still mostly theoretical exploration for you?",
      "timestamp": "2025-12-07T03:12:46.416Z"
    },
    {
      "role": "user",
      "content": "It's mostly exploration at this point.",
      "timestamp": "2025-12-07T03:13:15.992Z"
    },
    {
      "role": "assistant",
      "content": "So you're in the early stages of figuring this out, which makes the directional uncertainty totally understandable.\n\nWhen you imagine the next version of this course - whether it's redesigned from scratch or otherwise - are you feeling more energized by the possibilities, more anxious about all the challenges we've discussed, or somewhere in between?",
      "timestamp": "2025-12-07T03:13:20.189Z"
    },
    {
      "role": "user",
      "content": "I keep hearing people say how cool it's going to be, and I'm willing to give it a shot.  I'm just not sure what that looks like or how I get there.",
      "timestamp": "2025-12-07T03:14:06.764Z"
    },
    {
      "role": "assistant",
      "content": "That willingness to give it a shot, even with all the uncertainty, says a lot. You're hearing the enthusiasm but need to figure out what it actually means for your specific situation.\n\nWhat would help you most right now - seeing concrete examples of how other CS educators are using AI in similar courses, connecting with a community of peers who are wrestling with the same questions, or having some structured support to work through designing your own approach?",
      "timestamp": "2025-12-07T03:14:11.603Z"
    },
    {
      "role": "user",
      "content": "Working with someone I think would help.",
      "timestamp": "2025-12-07T03:14:46.637Z"
    },
    {
      "role": "assistant",
      "content": "That makes a lot of sense - having someone to think through all these moving pieces with rather than trying to figure it out solo.\n\nNextEd offers a few different ways to work with people: there's an Adoption Clinic that's an intensive cohort experience where you redesign a course with other faculty, one-on-one consultation for more individualized support, a Policy Board for navigating institutional guidance, or structured research pilot support. Which of those sounds most appealing to you, or would you want something different entirely?",
      "timestamp": "2025-12-07T03:14:51.876Z"
    },
    {
      "role": "user",
      "content": "the adoption clinic sounds helpful",
      "timestamp": "2025-12-07T03:15:25.679Z"
    },
    {
      "role": "assistant",
      "content": "What would make that cohort experience worth your time? Is it the structured process of redesigning, learning from other faculty facing similar challenges, or something else about working through this with a group?",
      "timestamp": "2025-12-07T03:15:29.392Z"
    },
    {
      "role": "user",
      "content": "I feel like it might give me a path forward.",
      "timestamp": "2025-12-07T03:15:55.475Z"
    },
    {
      "role": "assistant",
      "content": "I think I have everything I need. If you have a few minutes, I'd like to revisit your concern about student resistance to AI - you mentioned many students in your program are vehemently against it, and I'm curious what you think would need to be true for them to engage with AI integration in a way that feels authentic rather than imposed. Or we can wrap up whenever you're ready.",
      "timestamp": "2025-12-07T03:16:01.179Z"
    },
    {
      "role": "user",
      "content": "On some level I suspect their resistance is politically motivated.  It seems based in fear.",
      "timestamp": "2025-12-07T03:16:45.699Z"
    },
    {
      "role": "assistant",
      "content": "That fear component is really important - fear often makes it harder to engage with the actual learning opportunities, regardless of what's driving it.\n\nWhen you think about designing a course that includes AI, do you see yourself needing to address that fear directly - maybe acknowledging their concerns upfront - or would you rather design in a way that lets students experience the benefits first before they even realize they're working with AI?",
      "timestamp": "2025-12-07T03:16:50.020Z"
    },
    {
      "role": "user",
      "content": "I think addressing the fear is important.",
      "timestamp": "2025-12-07T03:17:13.793Z"
    },
    {
      "role": "assistant",
      "content": "That's a thoughtful approach - acknowledging the fear rather than trying to work around it.\n\nWhat do you think would help students feel heard about their concerns while still creating space for them to engage with AI as a learning tool? Is it more about creating discussion space for their objections, showing them how AI could align with values they already hold, or something else entirely?",
      "timestamp": "2025-12-07T03:17:17.720Z"
    },
    {
      "role": "user",
      "content": "I honestly don't know.",
      "timestamp": "2025-12-07T03:17:39.132Z"
    },
    {
      "role": "assistant",
      "content": "That honesty is really valuable - these are genuinely hard questions without clear answers.\n\nSounds good. Let me generate a summary of what we've discussed.\n\n---\n\n## Summary: SE 266 Game Scripting with Unity\n\n**Course Context:**\n- 200-level introductory course with OOP prerequisite\n- Unity's complexity makes it challenging to cover everything in one semester\n- Core learning goal: Students should understand software as building blocks and learn architectural thinking over specific syntax\n\n**Current Challenges:**\n- Unity's overwhelming complexity (3D environments, lights, materials, animations, scripting)\n- Students struggle with all the moving parts simultaneously\n- Limited time to cover Unity editor basics, let alone deeper game design concepts\n\n**AI Integration Concerns:**\n- **Student access**: Equity issues around AI tool availability\n- **Student resistance**: Many students \"vehemently against AI,\" resistance appears fear-based and possibly politically motivated\n- **Policy uncertainty**: Institutional AI policies exist but aren't well understood; Copilot is available but boundaries are unclear\n- **Academic integrity**: Plagiarism concerns, students potentially using AI to generate code they don't understand\n- **Ethical concerns**: Questions about AI training data and whether ideas were \"stolen\"\n\n**Current Status & Direction:**\n- Mostly theoretical exploration of AI integration so far\n- Willing to experiment despite concerns - \"willing to give it a shot\"\n- Open to complete course redesign from scratch\n- Biggest obstacle: \"knowing which direction to move in first\"\n- Interested in NextEd's Adoption Clinic for structured support and community\n\n**Key Tension:**\nBalancing excitement about AI possibilities with multiple legitimate concerns (institutional, ethical, pedagogical) while navigating student resistance in a complex technical environment.\n\n**Next Steps:**\nConsidering Adoption Clinic participation to find \"a path forward\" through collaborative course redesign process.",
      "timestamp": "2025-12-07T03:17:50.468Z"
    },
    {
      "role": "user",
      "content": "That looks good to me.  Are we done?",
      "timestamp": "2025-12-07T03:18:24.873Z"
    },
    {
      "role": "assistant",
      "content": "Yes, we're done! Thanks for taking the time to explore all of this with me. You've got a lot of thoughtful considerations around AI integration, and it sounds like the Adoption Clinic could be a good way to work through them with others facing similar challenges.\n\nIf you decide you want to learn more about the Adoption Clinic or any of the other support options, you can reach out to NextEd. Good luck with SE 266!",
      "timestamp": "2025-12-07T03:18:29.371Z"
    }
  ],
  "summary": {
    "initial": "I just had a really thoughtful conversation with Mark Gill about SE 266, Game Scripting with Unity. This is a 200-level introductory course where students come in with object-oriented programming under their belt, but it's their first dive into game development. Mark is dealing with Unity's overwhelming complexity - trying to teach not just the editor interface, but also 3D environments, lighting, materials, animations, and scripting all in one semester. What's really striking is his clarity about the deeper learning goal: he wants students to understand software as building blocks, to grasp that learning how to assemble components is more important than the code inside them. It's about architectural thinking that will transfer everywhere, not just Unity-specific skills. But his students get lost in all the moving parts - the complexity of the 3D environment makes it hard for them to see the forest for the trees.\n\nMark's concerns span both institutional and pedagogical territory pretty evenly. He's navigating unclear AI policies at his institution (they have Copilot, but he doesn't fully understand what else is available or what the boundaries are), while also wrestling with genuine pedagogical questions about how AI fits into his teaching philosophy. The policy uncertainty creates barriers rather than helpful guardrails, making it hard to experiment thoughtfully.\n\nHis specific concerns run deep and interconnect in complex ways. Student access is a big worry - both the equity issues around who can afford AI tools and the fact that many students in his program are \"vehemently against AI.\" He sees this resistance as fear-based and possibly politically motivated, which adds another layer of challenge. Then there's the whole academic integrity maze - he's worried about students using AI to generate code they don't understand, which would completely undermine his building blocks learning goal. On top of that, he's grappling with broader ethical questions about AI training data and whether these systems essentially \"stole\" ideas. These aren't abstract concerns for him - they're all interconnected obstacles that make it hard to see a clear path forward.\n\nWe didn't dive deeply into his current assessment methods, but the academic integrity concerns suggest he's thinking about how AI might affect his ability to gauge whether students truly understand the architectural thinking he's trying to teach. If students can generate code without understanding the building block concepts, his whole pedagogical approach gets undermined.\n\nMark is cautiously open but genuinely uncertain. He keeps hearing people say how cool AI integration is going to be, and he's \"willing to give it a shot,\" but he's carrying a lot of competing concerns. He doesn't see AI as fundamentally incompatible with what he's trying to teach - it's just something \"we have to figure out.\" There's a sense of inevitability mixed with uncertainty. He's even open to redesigning the entire course from scratch, which suggests more readiness for substantial change than I initially expected.\n\nHis biggest practical obstacle isn't time or expertise - it's directional uncertainty. He said the biggest challenge is \"just knowing which direction to move in first.\" With all these competing concerns and constraints, he can't see what a good first step looks like. He's mostly in exploration mode right now, theoretical rather than hands-on with AI tools.\n\nMark knows he needs support to work through this complexity. When I asked what would help most, he was clear that working with someone would be valuable. He's interested in NextEd's Adoption Clinic specifically because he thinks it might \"give me a path forward.\" The collaborative, cohort-based approach appeals to him - having structured support to work through the redesign process with other faculty facing similar challenges.\n\nI think Mark is a good fit for the Adoption Clinic. He's past the \"fundamentally opposed\" stage and has moved into genuine exploration mode. He's willing to experiment and even redesign from scratch, but he needs the structure and community support that the clinic provides. His concerns are legitimate and complex, but they're not showstoppers - they're exactly the kind of challenges that benefit from working through with peers and facilitators. He recognizes that addressing student fear and resistance needs to be part of any solution, which shows he's thinking systemically about implementation. The timing seems right - he's ready for something more substantial than just seeing examples or having theoretical discussions.\n\nDoes this accurately capture our conversation? Anything to add or clarify?",
    "confirmed": "I just had a really thoughtful conversation with Mark Gill about SE 266, Game Scripting with Unity. This is a 200-level introductory course where students come in with object-oriented programming under their belt, but it's their first dive into game development. Mark is dealing with Unity's overwhelming complexity - trying to teach not just the editor interface, but also 3D environments, lighting, materials, animations, and scripting all in one semester. What's really striking is his clarity about the deeper learning goal: he wants students to understand software as building blocks, to grasp that learning how to assemble components is more important than the code inside them. It's about architectural thinking that will transfer everywhere, not just Unity-specific skills. But his students get lost in all the moving parts - the complexity of the 3D environment makes it hard for them to see the forest for the trees.\n\nMark's concerns span both institutional and pedagogical territory pretty evenly. He's navigating unclear AI policies at his institution (they have Copilot, but he doesn't fully understand what else is available or what the boundaries are), while also wrestling with genuine pedagogical questions about how AI fits into his teaching philosophy. The policy uncertainty creates barriers rather than helpful guardrails, making it hard to experiment thoughtfully.\n\nHis specific concerns run deep and interconnect in complex ways. Student access is a big worry - both the equity issues around who can afford AI tools and the fact that many students in his program are \"vehemently against AI.\" He sees this resistance as fear-based and possibly politically motivated, which adds another layer of challenge. Then there's the whole academic integrity maze - he's worried about students using AI to generate code they don't understand, which would completely undermine his building blocks learning goal. On top of that, he's grappling with broader ethical questions about AI training data and whether these systems essentially \"stole\" ideas. These aren't abstract concerns for him - they're all interconnected obstacles that make it hard to see a clear path forward.\n\nWe didn't dive deeply into his current assessment methods, but the academic integrity concerns suggest he's thinking about how AI might affect his ability to gauge whether students truly understand the architectural thinking he's trying to teach. If students can generate code without understanding the building block concepts, his whole pedagogical approach gets undermined.\n\nMark is cautiously open but genuinely uncertain. He keeps hearing people say how cool AI integration is going to be, and he's \"willing to give it a shot,\" but he's carrying a lot of competing concerns. He doesn't see AI as fundamentally incompatible with what he's trying to teach - it's just something \"we have to figure out.\" There's a sense of inevitability mixed with uncertainty. He's even open to redesigning the entire course from scratch, which suggests more readiness for substantial change than I initially expected.\n\nHis biggest practical obstacle isn't time or expertise - it's directional uncertainty. He said the biggest challenge is \"just knowing which direction to move in first.\" With all these competing concerns and constraints, he can't see what a good first step looks like. He's mostly in exploration mode right now, theoretical rather than hands-on with AI tools.\n\nMark knows he needs support to work through this complexity. When I asked what would help most, he was clear that working with someone would be valuable. He's interested in NextEd's Adoption Clinic specifically because he thinks it might \"give me a path forward.\" The collaborative, cohort-based approach appeals to him - having structured support to work through the redesign process with other faculty facing similar challenges.\n\nI think Mark is a good fit for the Adoption Clinic. He's past the \"fundamentally opposed\" stage and has moved into genuine exploration mode. He's willing to experiment and even redesign from scratch, but he needs the structure and community support that the clinic provides. His concerns are legitimate and complex, but they're not showstoppers - they're exactly the kind of challenges that benefit from working through with peers and facilitators. He recognizes that addressing student fear and resistance needs to be part of any solution, which shows he's thinking systemically about implementation. The timing seems right - he's ready for something more substantial than just seeing examples or having theoretical discussions.\n\nDoes this accurately capture our conversation? Anything to add or clarify?",
    "user_edits": null
  },
  "completed_time": "2025-12-07T11:09:11.641Z",
  "last_updated": "2025-12-07T11:09:11.641Z"
}